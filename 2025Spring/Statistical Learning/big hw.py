# ========== Wine Quality Analysis ==========
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.decomposition import PCA
import os

# 1. Data Loading & Validation ==============================
print("=" * 50)
print("STEP 1: DATA LOADING")
print("=" * 50)

# å®šä¹‰é¢„æœŸçš„åˆ—åï¼ˆåŸºäºå›¾ç‰‡ä¿¡æ¯ï¼‰
expected_columns = [
    'fixed acidity', 'volatile acidity', 'citric acid',
    'residual sugar', 'chlorides', 'free sulfur dioxide',
    'total sulfur dioxide', 'density', 'pH', 'sulphates',
    'alcohol', 'quality'
]

# è·å–å½“å‰å·¥ä½œç›®å½•
current_dir = os.getcwd()
print(f"Current working directory: {current_dir}")

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
file_path = os.path.join(current_dir, 'winequality-red.csv')
print(f"Looking for file at: {file_path}")

if not os.path.exists(file_path):
    print(f"âŒ ERROR: File not found at {file_path}")
    exit()

# å°è¯•ä¸åŒçš„åˆ†éš”ç¬¦åŠ è½½æ•°æ®
try:
    # å°è¯•åˆ†å·åˆ†éš”ç¬¦ï¼ˆåŸºäºå›¾ç‰‡ä¿¡æ¯ï¼‰
    df = pd.read_csv(file_path, sep=';')
    print("Attempted separator: semicolon (;)")

    # éªŒè¯åˆ—å
    missing_cols = [col for col in expected_columns if col not in df.columns]
    if missing_cols:
        print(f"âŒ Missing columns with semicolon separator: {missing_cols}")

        # å°è¯•é€—å·åˆ†éš”ç¬¦
        df = pd.read_csv(file_path, sep=',')
        print("Attempted separator: comma (,)")

        # å†æ¬¡éªŒè¯åˆ—å
        missing_cols = [col for col in expected_columns if col not in df.columns]
        if missing_cols:
            print(f"âŒ Missing columns with comma separator: {missing_cols}")
            print("ğŸ’¡ TIP: Check actual file content and separator")
            exit()

    print("âœ… Data loaded successfully!")
    print(f"Dataset shape: {df.shape}")
    print("\nFirst 3 rows:")
    print(df.head(3))

except Exception as e:
    print(f"âŒ Data loading failed: {str(e)}")
    exit()

# 2. Data Preprocessing =====================================
print("\n" + "=" * 50)
print("STEP 2: DATA PREPROCESSING")
print("=" * 50)

# æ£€æŸ¥æ•°æ®ç±»å‹
print("\nData types before conversion:")
print(df.dtypes)

# è½¬æ¢æ•°æ®ç±»å‹ä¸ºæ•°å€¼å‹
df = df.apply(pd.to_numeric, errors='coerce')

# æ£€æŸ¥è½¬æ¢åçš„æ•°æ®ç±»å‹
print("\nData types after conversion:")
print(df.dtypes)

# æ•°æ®æ¸…æ´—
initial_count = len(df)
df_clean = df.dropna().drop_duplicates()
cleaned_count = len(df_clean)

print(f"\nInitial rows: {initial_count}")
print(f"After cleaning: {cleaned_count} rows")
print(f"Removed: {initial_count - cleaned_count} rows (missing values and duplicates)")

# 3. Exploratory Analysis ===================================
print("\n" + "=" * 50)
print("STEP 3: EXPLORATORY ANALYSIS")
print("=" * 50)

# è´¨é‡åˆ†å¸ƒåˆ†æ
plt.figure(figsize=(10, 6))
sns.countplot(x='quality', data=df_clean, palette='viridis')
plt.title('Wine Quality Distribution')
plt.xlabel('Quality Score')
plt.ylabel('Count')
plt.savefig('quality_distribution.png')
plt.show()

# 4. Correlation Analysis ===================================
print("\n" + "=" * 50)
print("STEP 4: CORRELATION ANALYSIS")
print("=" * 50)

# è®¡ç®—ç›¸å…³æ€§
corr_matrix = df_clean.corr(numeric_only=True)

# è¾“å‡ºä¸è´¨é‡ç›¸å…³æ€§æœ€é«˜çš„ç‰¹å¾
quality_corr = corr_matrix['quality'].sort_values(ascending=False)
print("\nCorrelation with Quality:")
print(quality_corr)

# å¯è§†åŒ–ç›¸å…³æ€§çŸ©é˜µ
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix,
            annot=True,
            cmap='coolwarm',
            fmt=".2f",
            annot_kws={"size": 8},
            mask=np.triu(np.ones_like(corr_matrix, dtype=bool)))
plt.title('Feature Correlation Matrix')
plt.tight_layout()
plt.savefig('correlation_matrix.png')
plt.show()

# 5. K-Means Clustering Analysis ============================
print("\n" + "=" * 50)
print("STEP 5: K-MEANS CLUSTERING")
print("=" * 50)

# ç‰¹å¾é€‰æ‹© & æ ‡å‡†åŒ–
features = df_clean.columns.drop('quality')
X = df_clean[features]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# è‚˜éƒ¨æ³•åˆ™åˆ†æ
inertias = []
k_range = range(1, 11)

plt.figure(figsize=(10, 6))
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    inertias.append(kmeans.inertia_)

plt.plot(k_range, inertias, 'bo-', markersize=8)
plt.xticks(k_range)
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal Cluster Number')
plt.grid(True)
plt.savefig('elbow_method.png')
plt.show()

# é€‰æ‹©æœ€ä½³èšç±»æ•°ï¼ˆè¿™é‡Œé€‰æ‹©3ï¼Œä½†å®é™…åº”æ ¹æ®è‚˜éƒ¨æ³•åˆ™ç»“æœè°ƒæ•´ï¼‰
best_k = 3
print(f"\nSelected number of clusters: {best_k}")

# åº”ç”¨K-Meansèšç±»
kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)
cluster_labels = kmeans.fit_predict(X_scaled)
df_clean['Cluster'] = cluster_labels

# è®¡ç®—è½®å»“ç³»æ•°
silhouette_avg = silhouette_score(X_scaled, cluster_labels)
print(f"Silhouette Score: {silhouette_avg:.3f}")

# 6. Cluster Analysis =======================================
print("\n" + "=" * 50)
print("STEP 6: CLUSTER ANALYSIS")
print("=" * 50)

# èšç±»åˆ†å¸ƒ
print("\nCluster Distribution:")
print(df_clean['Cluster'].value_counts().sort_index())

# èšç±»è´¨é‡åˆ†æ
print("\nQuality by Cluster:")
print(df_clean.groupby('Cluster')['quality'].agg(['mean', 'median', 'std']))

# èšç±»ç‰¹å¾åˆ†æ
print("\nCluster Characteristics:")
cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)
cluster_centers_df = pd.DataFrame(cluster_centers, columns=features)
print(cluster_centers_df)

# 7. Visualization ==========================================
print("\n" + "=" * 50)
print("STEP 7: VISUALIZATION")
print("=" * 50)

# PCAé™ç»´å¯è§†åŒ–
pca = PCA(n_components=2)
principal_components = pca.fit_transform(X_scaled)

plt.figure(figsize=(10, 6))
sns.scatterplot(x=principal_components[:, 0],
                y=principal_components[:, 1],
                hue=cluster_labels,
                palette='viridis',
                s=80,
                edgecolor='black')
plt.title(f'PCA Cluster Visualization (Explained Variance: {pca.explained_variance_ratio_.sum():.1%})')
plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')
plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')
plt.legend(title='Cluster')
plt.savefig('pca_clusters.png')
plt.show()

# ç‰¹å¾ç®±çº¿å›¾
plt.figure(figsize=(16, 12))
for i, feature in enumerate(features, 1):
    plt.subplot(3, 4, i)
    sns.boxplot(x='Cluster', y=feature, data=df_clean)
    plt.title(feature)
plt.tight_layout()
plt.suptitle('Feature Distribution by Cluster', y=1.02)
plt.savefig('cluster_features.png')
plt.show()

# 8. Save Results ===========================================
df_clean.to_csv('clustered_wine_data.csv', index=False)
print("\nResults saved to 'clustered_wine_data.csv'")
print("=" * 50)
print("ANALYSIS COMPLETED SUCCESSFULLY!")
print("=" * 50)